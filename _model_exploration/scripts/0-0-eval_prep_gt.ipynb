{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare GT for quantitative evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean GT\n",
    "\n",
    "- Clean up spelling mistakes\n",
    "- Merge classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "import difflib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from shapely.validation import explain_validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../data/GT/20231004/0-0-almost_raw/\"\n",
    "target_dir = \"../data/GT/20231004/0-cleaned\"\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "    print(f\"The directory {target_dir} was created.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get set (all_cats) of all the different class strings present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nancount = 0\n",
    "\n",
    "all_cats = set()\n",
    "for root, dir, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".shp\"):\n",
    "                continue\n",
    "                \n",
    "            gt = gpd.read_file(os.path.join(root, file))\n",
    "            # for cat in list(gt[\"CLASSE_SEN\"]):\n",
    "            for row in gt.iterrows():\n",
    "                cat = row[1][\"CLASSE_SEN\"]\n",
    "                all_cats.add(cat)\n",
    "\n",
    "                if not isinstance(cat, str):\n",
    "                    nancount += 1\n",
    "                    assert row[1][\"geometry\"] is None\n",
    "                \n",
    "                if not explain_validity(row[1][\"geometry\"]):\n",
    "                    print(file)\n",
    "\n",
    "                \n",
    "print(f'{nancount = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{all_cats = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of typos and merge classes that are not present in IGN classes\n",
    "Use difflibs get_close_matches() to get close matches to the \"real\" \n",
    "categories and store them in as dictionary {(false) string: true string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cats = [\"batiment\", \"eau_bassin\", \"eau_naturelle\", \"roche_dure_meuble\",\n",
    "    \"roseliere\", \"serre_permanente\", \"sol_agricole\", \"sol_bache\", \"sol_divers\",\n",
    "    \"sol_neige\", \"sol_serre_temporaire\", \"sol_vegetalise\", \"sol_vigne\",\n",
    "    \"surface_beton\", \"surface_non_beton\", \"surface_riparienne\", \"toit_vegetalise\"]\n",
    "\n",
    "all_cats = [cat for cat in all_cats if isinstance(cat, str)] \n",
    "all_cats = list(all_cats)\n",
    "\n",
    "if len(all_cats) == len(real_cats):\n",
    "    print(\"Classses seem to be consistent, no string matching required\") # Review: why does this test insure that there is no typos?\n",
    "    clean_dic = {cat: cat for cat in all_cats}\n",
    "\n",
    "else:\n",
    "    # filter out nans (are floats)\n",
    "    found_cats = []\n",
    "\n",
    "    clean_dic = {}\n",
    "    for real_cat in real_cats:\n",
    "        \n",
    "        matches = difflib.get_close_matches(real_cat, all_cats, n=5, cutoff=0.8)\n",
    "        for match in matches:\n",
    "            clean_dic[match] = real_cat\n",
    "\n",
    "        found_cats.extend(matches)\n",
    "\n",
    "    # assert that for all cats exactly one match has been found\n",
    "    assert len(found_cats) == len(all_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge_dic = {\n",
    "#     \"toit_vegetalise\": \"batiment\",\n",
    "#     \"roseliere\": \"eau\",\n",
    "#     \"terrain_de_sport\": \"terre_vegetalisee\",\n",
    "#     \"infrastructure\": \"revetement_impermeable\"\n",
    "# }\n",
    "\n",
    "# merge_dic = {\n",
    "#     \"toit_vegetalise\": \"batiment\",\n",
    "#     \"roche_dure_meuble\": \"surface_non_beton\",\n",
    "#     \"roseliere\": \"eau_naturelle\",\n",
    "#     \"sol_serre_temporaire\": \"serre_permanente\",\n",
    "#     \"sol_bache\": \"sol_agricole\",\n",
    "#     \"surface_riparienne\": \"sol_vegetalise\"\n",
    "#     # \"terrain_de_sport\": \"sol_vegetalise\",\n",
    "#     # \"eau_bassin\": \"eau_naturelle\",\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new column with correct strings and merged classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(x):\n",
    "#     new = []\n",
    "#     for row in x[\"CLASSE_SEN\"]:\n",
    "#         if isinstance(row, float): # in case of nan (is a float)\n",
    "#             new.append(\"unknown\")\n",
    "#             continue\n",
    "#         new.append(clean_dic[row])\n",
    "#     return new\n",
    "\n",
    "# def merge(x):\n",
    "#     new = []\n",
    "#     # for row in x[\"CLEAN_CLASSE_SEN\"]:\n",
    "#     for row in x[\"CLASSE_SEN\"]:\n",
    "#         if row in merge_dic:\n",
    "#             new.append(merge_dic[row])\n",
    "#         else:\n",
    "#             new.append(row)\n",
    "#     return new\n",
    "\n",
    "class_mapping = {\n",
    "    np.nan: 0,\n",
    "    \"batiment\": 1,\n",
    "    \"toit_vegetalise\": 2,\n",
    "    \"surface_non_beton\": 3,\n",
    "    \"surface_beton\": 4,\n",
    "    \"eau_bassin\": 5,\n",
    "    \"roche_dure_meuble\": 6,\n",
    "    \"eau_naturelle\": 7,\n",
    "    \"roseliere\": 8,\n",
    "    \"sol_neige\": 9,\n",
    "    \"sol_vegetalise\": 10,\n",
    "    \"surface_riparienne\": 11,\n",
    "    \"sol_divers\": 12,\n",
    "    \"sol_vigne\": 13,\n",
    "    \"sol_agricole\": 14,\n",
    "    \"sol_bache\": 15,\n",
    "    \"sol_serre_temporaire\": 16,\n",
    "    \"serre_permanente\": 17\n",
    "}\n",
    "package_mapping = {\n",
    "    0: 0, 1: 1, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 6, 9: 7, 10: 8,\n",
    "    11: 8, 12: 8, 13: 9, 14: 10, 15: 10, 16: 10, 17: 11\n",
    "}\n",
    "\n",
    "soil_classes = [9, 10, 12, 13, 14, 15, 16]\n",
    "\n",
    "for root, dir, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".shp\"):\n",
    "                continue\n",
    "            \n",
    "            gt = gpd.read_file(os.path.join(root, file))\n",
    "\n",
    "            # gt[\"CLEAN_CLASSE_SEN\"] = clean(gt)\n",
    "            # gt[\"CLEAN_CLASSE_SEN\"] = merge(gt)\n",
    "            \n",
    "            gt[\"CLASSE_SEN_ID\"] = gt.apply(\n",
    "                lambda x: class_mapping[x[\"CLASSE_SEN\"]], axis=1)\n",
    "            gt[\"SOIL\"] = gt.apply(\n",
    "                lambda x: x[\"CLASSE_SEN_ID\"] in soil_classes, axis=1)\n",
    "            gt[\"package_id\"] = gt.apply(\n",
    "                lambda x: package_mapping[x[\"CLASSE_SEN_ID\"]], axis=1)\n",
    "\n",
    "            \n",
    "            gt[\"geometry\"] = gt.make_valid()\n",
    "\n",
    "            gt = gt.dropna(subset = [\"CLASSE_SEN\"])\n",
    "            gt = gt.explode(index_parts=False)\n",
    "            gt = gt.loc[gt[\"geometry\"].geom_type=='Polygon']\n",
    "            gt.to_file(os.path.join(target_dir, file.rstrip(\".shp\")+\".gpkg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/rasterize_gt.py --config_file ../config/config-eval_gt.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/reclassify.py --config_file ../config/config-eval_gt.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cut tiff to predefined grid of Daniel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/cut_tiff_to_grid.py --config_file ../config/config-eval_gt.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Rescale GT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "67c683be3b89053d7ca5cf9ab92fc1f76d72010376a6f7730bc4c074221af5a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
