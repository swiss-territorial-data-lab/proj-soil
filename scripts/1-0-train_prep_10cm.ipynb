{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset for Fine-Tuning of the HEIG-VD Model with the 10cm resolution dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "projsoilsroot = \"/proj-soil\"\n",
    "config_train_gt = os.path.join(projsoilsroot, \"config/train\", \"config-train_gt-10cm.yaml\")\n",
    "config_train_scratch = os.path.join(projsoilsroot, \"config/train\", \"config-train_scratch-10cm.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Snap to 10cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "root = os.path.join(projsoilsroot,\"data/GT/20240216/0-0-0-raw/test\")\n",
    "out_folder = os.path.join(projsoilsroot,\"data/GT/20240216/1-snapped\")\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "    print(f\"The directory {out_folder} was created.\")\n",
    "\n",
    "for file in os.listdir(root):\n",
    "    if not file.endswith(\".shp\"):\n",
    "        continue\n",
    "\n",
    "    gt = gpd.read_file(os.path.join(root, file))\n",
    "    bbox = list(gt.total_bounds)\n",
    "\n",
    "    deviation_from_snap = np.array(bbox).round(1) - bbox\n",
    "    plus_xmin, plus_ymin, _, _ = deviation_from_snap\n",
    "\n",
    "    gt.geometry = gt.geometry.translate(plus_xmin, plus_ymin)\n",
    "    gt.to_file(os.path.join(out_folder, file.replace(\".shp\", \".gpkg\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assign classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = os.path.join(projsoilsroot,\"data/GT/20240216/1-snapped\")\n",
    "out_folder = os.path.join(projsoilsroot,\"data/GT/20240216/2-cleaned\")\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "    print(f\"The directory {out_folder} was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    np.nan: 0,\n",
    "    \"batiment\": 1,\n",
    "    \"toit_vegetalise\": 2,\n",
    "    \"surface_non_beton\": 3,\n",
    "    \"surface_beton\": 4,\n",
    "    \"eau_bassin\": 5,\n",
    "    \"roche_dure_meuble\": 6,\n",
    "    \"eau_naturelle\": 7,\n",
    "    \"roseliere\": 8,\n",
    "    \"sol_neige\": 9,\n",
    "    \"sol_vegetalise\": 10,\n",
    "    \"surface_riparienne\": 11,\n",
    "    \"sol_divers\": 12,\n",
    "    \"sol_vigne\": 13,\n",
    "    \"sol_agricole\": 14,\n",
    "    \"sol_bache\": 15,\n",
    "    \"sol_serre_temporaire\": 16,\n",
    "    \"serre_permanente\": 17\n",
    "}\n",
    "\n",
    "soil_classes = [9, 10, 12, 13, 14, 15, 16]\n",
    "\n",
    "package_mapping = {\n",
    "    0: 0, 1: 1, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 6, 9: 7, 10: 8,\n",
    "    11: 8, 12: 8, 13: 9, 14: 10, 15: 10, 16: 10, 17: 11\n",
    "}\n",
    "\n",
    "cl12_mapping = {\n",
    "    0: 0, \n",
    "    1: 1, # batiment\n",
    "    2: 1, # toit_vegetalise -> batiment\n",
    "    3: 2, # surface_non_beton\n",
    "    4: 3, # surface_beton\n",
    "    5: 5, # eau_bassin -> eau_naturelle\n",
    "    6: 4, # roche_dure_meuble\n",
    "    7: 5, # eau_naturelle\n",
    "    8: 6, # roseliere\n",
    "    9: 7, # sol_neige\n",
    "    10: 8, # sol_vegetalise\n",
    "    11: 8, # surface_riparienne -> sol_vegetalise\n",
    "    12: 9, # sol_divers\n",
    "    13: 10, # sol_vigne\n",
    "    14: 11, # sol_agricole\n",
    "    15: 12, # sol_bache\n",
    "    16: 12, # sol_serre_temporaire -> sol_bache\n",
    "    17: 1, # serre_permanente -> batiment\n",
    "    }\n",
    "\n",
    "\n",
    "for root, dir, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            if not file.endswith((\".shp\", \".gpkg\")):\n",
    "                continue\n",
    "            \n",
    "            gt = gpd.read_file(os.path.join(root, file))\n",
    "\n",
    "            gt[\"CLASSE_SEN_ID\"] = gt.apply(\n",
    "                lambda x: class_mapping[x[\"CLASSE_SEN\"]], axis=1)\n",
    "            gt[\"package_id\"] = gt.apply(\n",
    "                lambda x: package_mapping[x[\"CLASSE_SEN_ID\"]], axis=1)\n",
    "            gt[\"cl12_id\"] = gt.apply(\n",
    "                lambda x: cl12_mapping[x[\"CLASSE_SEN_ID\"]], axis=1)\n",
    "            gt[\"SOIL\"] = gt.apply(\n",
    "                lambda x: x[\"CLASSE_SEN_ID\"] in soil_classes, axis=1)\n",
    "\n",
    "\n",
    "            # gt[\"geometry\"] = gt.make_valid()\n",
    "\n",
    "            gt = gt.dropna(subset = [\"CLASSE_SEN_ID\"])\n",
    "            gt = gt.explode(index_parts=False)\n",
    "            gt = gt.loc[gt[\"geometry\"].geom_type=='Polygon']\n",
    "\n",
    "            gt = gt[['CLASSE_SEN', 'CLASSE_SEN_ID', 'package_id', 'cl12_id', 'SOIL', 'geometry']]\n",
    "\n",
    "            if file.endswith(\".shp\"):\n",
    "                gt.to_file(os.path.join(out_folder, file.rstrip(\".shp\")+\".gpkg\"), driver=\"GPKG\")\n",
    "            else:\n",
    "                gt.to_file(os.path.join(out_folder, file), driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/rasterize_gt.py --config_file {config_train_gt}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cut tiff to predefined grid of Daniel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/cut_tiff_to_grid.py --config_file {config_train_gt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RGBI -> RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/rgbi2rgb.py --config_file {config_train_scratch}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ensure every file has resolution 10cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/rescale_tif.py --config_file {config_train_scratch}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cut tiff to grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/cut_tiff_to_grid.py --config_file {config_train_scratch}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utilities/random_split.py --config_file {config_train_gt}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "67c683be3b89053d7ca5cf9ab92fc1f76d72010376a6f7730bc4c074221af5a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
